{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b21acf48-994c-47ee-af93-8025f9b78719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import rdflib\n",
    "from rdflib import Graph, URIRef, Literal, Namespace, BNode, Dataset\n",
    "from rdflib.namespace import SKOS, DCTERMS, DCMITYPE, RDF, RDFS, XSD, PROV, SDO, TIME, split_uri\n",
    "\n",
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from typing import Dict, Any, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6e0afa-aed6-4b58-a057-55f34e1e317c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening config file, the config structure is:\n",
    "# {\"openai_api_key\":\"......\"}\n",
    "\n",
    "config = open('config', 'r')\n",
    "config = json.load(config)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config['openai_api_key']\n",
    "os.environ['GEMINI_API_KEY'] = config['gemini_api_key']\n",
    "os.environ['XAI_API_KEY'] = config['xai_api_key']\n",
    "os.environ['NVIDIA_API_KEY'] = config['nvidia_api_key']\n",
    "os.environ['DEEPSEEK_API_KEY'] = config['deepseek_api_key']\n",
    "os.environ['ANTHROPIC_API_KEY'] = config['claude_api_key']\n",
    "os.environ['DASHSCOPE_API_KEY'] = config['dashscope_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3308a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(data):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(data=data, format=\"turtle\")\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fcd845b-c183-4d6b-9bb5-bdbc96efd72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_rdf(rdf):\n",
    "    g = rdflib.Graph()\n",
    "    g.parse(data=rdf, format=\"turtle\")\n",
    "\n",
    "    for s, p, o in g:\n",
    "        print(s, p, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9838b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Namespaces\n",
    "she = Namespace(\"https://soilwise-he.github.io/soil-health#\")\n",
    "agrovoc = Namespace(\"http://aims.fao.org/aos/agrovoc/\")\n",
    "agrontology = Namespace(\"http://aims.fao.org/aos/agrontology#\")\n",
    "sio = Namespace(\"http://semanticscience.org/resource/\")\n",
    "glosis_lh = Namespace(\"http://w3id.org/glosis/model/layerhorizon/\")\n",
    "glosis_sp = Namespace(\"http://w3id.org/glosis/model/siteplot/\")\n",
    "qudt = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "unit = Namespace(\"http://qudt.org/vocab/unit/\")\n",
    "iso11074 = Namespace(\"https://data.geoscience.earth/ncl/ISO11074v2025/\")\n",
    "obo = Namespace(\"http://purl.obolibrary.org/obo/\")\n",
    "wdt = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
    "biolink = Namespace(\"https://w3id.org/biolink/vocab/\")\n",
    "afox = Namespace(\"http://purl.allotrope.org/ontologies/property#\")\n",
    "afor = Namespace(\"http://purl.allotrope.org/ontologies/result#\")\n",
    "sorelsc = Namespace(\"http://sweetontology.net/relaSci/\")\n",
    "sorelpr = Namespace(\"http://sweetontology.net/relaProvenance/\")\n",
    "sohuj = Namespace(\"http://sweetontology.net/humanJurisdiction/\")\n",
    "sorelph = Namespace(\"http://sweetontology.net/relaPhysical/\")\n",
    "sorelm = Namespace(\"http://sweetontology.net/relaMath/\")\n",
    "sorepsg = Namespace(\"http://sweetontology.net/reprSpaceGeometry/\")\n",
    "bao = Namespace(\"http://www.bioassayontology.org/bao#\")\n",
    "repr = Namespace(\"https://w3id.org/reproduceme#\")\n",
    "sorelch = Namespace(\"http://sweetontology.net/relaChemical/\")\n",
    "sorelsp = Namespace(\"http://sweetontology.net/relaSpace/\")\n",
    "om = Namespace(\"http://www.ontology-of-units-of-measure.org/resource/om-2/\")\n",
    "afop = Namespace(\"http://purl.allotrope.org/ontologies/process#\")\n",
    "gemet = Namespace(\"http://www.eionet.europa.eu/gemet/concept/\")\n",
    "inrae = Namespace(\"http://opendata.inrae.fr/thesaurusINRAE/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415ada89",
   "metadata": {},
   "source": [
    "### Vocabs or not vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd04df66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 10990 triples from soil_health_KG.ttl\n",
      "Found 494 unique concepts with exactMatch or closeMatch properties\n",
      "Successfully saved concept URIs to skos_concepts_with_matches.csv\n"
     ]
    }
   ],
   "source": [
    "def extract_skos_concepts_with_matches(ttl_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Extract SKOS concepts that have exactMatch or closeMatch properties\n",
    "    and save their URIs to a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        ttl_file_path (str): Path to the TTL file containing the RDF knowledge graph\n",
    "        output_csv_path (str): Path where the CSV file will be saved\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a graph and load the TTL file\n",
    "    g = Graph()\n",
    "    try:\n",
    "        g.parse(ttl_file_path, format='turtle')\n",
    "        print(f\"Successfully loaded {len(g)} triples from {ttl_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading TTL file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Define SKOS namespace\n",
    "    SKOS = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "    \n",
    "    # Set to store unique concept URIs\n",
    "    concepts_with_matches = set()\n",
    "    \n",
    "    # Query for concepts with exactMatch\n",
    "    exact_match_concepts = g.subjects(SKOS.exactMatch, None)\n",
    "    for concept in exact_match_concepts:\n",
    "        if isinstance(concept, URIRef):\n",
    "            concepts_with_matches.add(str(concept))\n",
    "    \n",
    "    # Query for concepts with closeMatch\n",
    "    close_match_concepts = g.subjects(SKOS.closeMatch, None)\n",
    "    for concept in close_match_concepts:\n",
    "        if isinstance(concept, URIRef):\n",
    "            concepts_with_matches.add(str(concept))\n",
    "    \n",
    "    # Convert to sorted list for consistent output\n",
    "    concepts_list = sorted(list(concepts_with_matches))\n",
    "    \n",
    "    print(f\"Found {len(concepts_list)} unique concepts with exactMatch or closeMatch properties\")\n",
    "    \n",
    "    # Save to CSV file\n",
    "    try:\n",
    "        with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            # Write header\n",
    "            writer.writerow(['concept_uri'])\n",
    "            # Write concept URIs\n",
    "            for concept_uri in concepts_list:\n",
    "                writer.writerow([concept_uri])\n",
    "        \n",
    "        print(f\"Successfully saved concept URIs to {output_csv_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file: {e}\")\n",
    "        return\n",
    "    \n",
    "    return concepts_list\n",
    "\n",
    "def extract_with_match_details(ttl_file_path, output_csv_path):\n",
    "    \"\"\"\n",
    "    Alternative version that also extracts the match details (what each concept matches to)\n",
    "    and the type of match (exact or close).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a graph and load the TTL file\n",
    "    g = Graph()\n",
    "    try:\n",
    "        g.parse(ttl_file_path, format='turtle')\n",
    "        print(f\"Successfully loaded {len(g)} triples from {ttl_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading TTL file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Define SKOS namespace\n",
    "    SKOS = Namespace(\"http://www.w3.org/2004/02/skos/core#\")\n",
    "    \n",
    "    # List to store detailed match information\n",
    "    match_details = []\n",
    "    \n",
    "    # Query for exactMatch relationships\n",
    "    for subject, predicate, obj in g.triples((None, SKOS.exactMatch, None)):\n",
    "        if isinstance(subject, URIRef):\n",
    "            match_details.append({\n",
    "                'concept_uri': str(subject),\n",
    "                'match_type': 'exactMatch',\n",
    "                'matched_uri': str(obj)\n",
    "            })\n",
    "    \n",
    "    # Query for closeMatch relationships\n",
    "    for subject, predicate, obj in g.triples((None, SKOS.closeMatch, None)):\n",
    "        if isinstance(subject, URIRef):\n",
    "            match_details.append({\n",
    "                'concept_uri': str(subject),\n",
    "                'match_type': 'closeMatch',\n",
    "                'matched_uri': str(obj)\n",
    "            })\n",
    "    \n",
    "    print(f\"Found {len(match_details)} total match relationships\")\n",
    "    \n",
    "    # Save detailed information to CSV\n",
    "    try:\n",
    "        df = pd.DataFrame(match_details)\n",
    "        df.to_csv(output_csv_path, index=False, encoding='utf-8')\n",
    "        print(f\"Successfully saved detailed match information to {output_csv_path}\")\n",
    "        \n",
    "        # Also print summary statistics\n",
    "        unique_concepts = df['concept_uri'].nunique()\n",
    "        exact_matches = len(df[df['match_type'] == 'exactMatch'])\n",
    "        close_matches = len(df[df['match_type'] == 'closeMatch'])\n",
    "        \n",
    "        print(f\"\\nSummary:\")\n",
    "        print(f\"- Unique concepts with matches: {unique_concepts}\")\n",
    "        print(f\"- Total exactMatch relationships: {exact_matches}\")\n",
    "        print(f\"- Total closeMatch relationships: {close_matches}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving CSV file: {e}\")\n",
    "        return\n",
    "    \n",
    "    return match_details\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Basic version - just concept URIs\n",
    "    ttl_file = \"soil_health_KG.ttl\"  # Replace with your TTL file path\n",
    "    output_csv = \"skos_concepts_with_matches.csv\"\n",
    "    \n",
    "    concepts = extract_skos_concepts_with_matches(ttl_file, output_csv)\n",
    "    \n",
    "    # Detailed version - with match information\n",
    "    # Uncomment the lines below if you want detailed match information\n",
    "    # detailed_output_csv = \"skos_concepts_detailed_matches.csv\"\n",
    "    # match_details = extract_with_match_details(ttl_file, detailed_output_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8019c135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded CSV with 684 rows\n",
      "Number of unique URIs in keywords column: 683\n",
      "Number of unique URIs in thesauri column: 494\n",
      "\n",
      "Set operation results:\n",
      "Union (all unique URIs): 788\n",
      "Intersection (URIs in both columns): 389\n",
      "Keywords only: 294\n",
      "Thesauri only: 105\n",
      "Saved 788 URIs to ./uri_union.csv\n",
      "Saved 389 URIs to ./uri_intersection.csv\n",
      "Saved 294 URIs to ./uri_keywords_only.csv\n",
      "Saved 105 URIs to ./uri_thesauri_only.csv\n",
      "\n",
      "All files saved successfully to directory: ./\n"
     ]
    }
   ],
   "source": [
    "def analyze_uri_sets(input_csv_path, output_dir=\"./\"):\n",
    "    \"\"\"\n",
    "    Analyze URIs from two columns and create separate CSV files for each set operation result.\n",
    "    \n",
    "    Args:\n",
    "        input_csv_path (str): Path to the input CSV file\n",
    "        output_dir (str): Directory to save output files\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read the CSV file\n",
    "    try:\n",
    "        df = pd.read_csv(input_csv_path)\n",
    "        print(f\"Successfully loaded CSV with {len(df)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading CSV file: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Check if required columns exist\n",
    "    if 'keywords' not in df.columns or 'thesauri' not in df.columns:\n",
    "        print(\"Error: Required columns 'keywords' and 'thesauri' not found in CSV\")\n",
    "        return\n",
    "    \n",
    "    # Remove NaN values and convert to sets\n",
    "    keywords_set = set(df['keywords'].dropna().astype(str))\n",
    "    thesauri_set = set(df['thesauri'].dropna().astype(str))\n",
    "    \n",
    "    print(f\"Number of unique URIs in keywords column: {len(keywords_set)}\")\n",
    "    print(f\"Number of unique URIs in thesauri column: {len(thesauri_set)}\")\n",
    "    \n",
    "    # Perform set operations\n",
    "    union_set = keywords_set.union(thesauri_set)\n",
    "    intersection_set = keywords_set.intersection(thesauri_set)\n",
    "    keywords_only = keywords_set - thesauri_set\n",
    "    thesauri_only = thesauri_set - keywords_set\n",
    "    \n",
    "    print(f\"\\nSet operation results:\")\n",
    "    print(f\"Union (all unique URIs): {len(union_set)}\")\n",
    "    print(f\"Intersection (URIs in both columns): {len(intersection_set)}\")\n",
    "    print(f\"Keywords only: {len(keywords_only)}\")\n",
    "    print(f\"Thesauri only: {len(thesauri_only)}\")\n",
    "    \n",
    "    # Save each set to a separate CSV file\n",
    "    sets_data = {\n",
    "        'union': union_set,\n",
    "        'intersection': intersection_set,\n",
    "        'keywords_only': keywords_only,\n",
    "        'thesauri_only': thesauri_only\n",
    "    }\n",
    "    \n",
    "    for set_name, uri_set in sets_data.items():\n",
    "        filename = f\"{output_dir}uri_{set_name}.csv\"\n",
    "        try:\n",
    "            df_temp = pd.DataFrame({'URI': sorted(uri_set)})\n",
    "            df_temp.to_csv(filename, index=False)\n",
    "            print(f\"Saved {len(uri_set)} URIs to {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\nAll files saved successfully to directory: {output_dir}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace with your actual file paths\n",
    "    input_file = \"matched_concepts.csv\"\n",
    "    output_directory = \"./\"  # Current directory, change as needed\n",
    "    \n",
    "    analyze_uri_sets(input_file, output_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d2b3d",
   "metadata": {},
   "source": [
    "#### LLM-as-a-judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b112477",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_voc = \"\"\"You are an expert AI assistant specializing in soil science and controlled vocabulary development. Your task is to analyze a given term and determine if it is suitable for inclusion in a formal, standardized soil science vocabulary.\n",
    "\n",
    "**Your Goal:**\n",
    "Classify each term you receive into one of two categories: \"Vocabulary\" or \"Un-vocabulary\".\n",
    "\n",
    "**Definitions and Rules:**\n",
    "\n",
    "1. **\"Vocabulary\" Term:**\n",
    "   \n",
    "   * Represents a standardized, reusable, and generic concept *within the domain of soil science*.\n",
    "   * It is often a general concept that can have specific instances, values, or measurements.\n",
    "   * It can be singular or plural.\n",
    "   * Abbreviations or standard acronyms that refer directly to those concepts (e.g. `SOC`, `DDT`).\n",
    "   * It should be a noun or a noun phrase that is broadly recognized and used in soil science literature, without evaluative or descriptive adjectives (avoid “high”, “moderate”, “low”, etc.).\n",
    "   * *Examples of Vocabulary Terms:* `soil organic carbon`, `cation exchange capacity`, `soil texture`, `bulk density`, `soil horizon`, `parent material`, `silt loam`.\n",
    "2. **\"Un-vocabulary\" Term:**\n",
    "   A term is classified as \"Un-vocabulary\" if it meets **any** of the following criteria:\n",
    "   \n",
    "   * **Evaluative/descriptive instances:** It represents a specific *measurement*, *qualitative state*, or *quantitative description* of a vocabulary term (e.g. “moderate soil organic carbon content”, “high bulk density”, “poor CEC”).\n",
    "   * **Too broad or out of scope:** The term is a generic concept that is not specific to soil science and lacks a direct, unique meaning within the domain (e.g. “time”, “location” when unqualified).\n",
    "   * **Context-specific phrases:** The term is phrased as a statement or sentence fragment rather than a standardized standalone noun concept (e.g. “agricultural area under severe erosion”).\n",
    "3. **Confidence:**\n",
    "   \n",
    "   * Provide a confidence score between 0 and 1 reflecting how certain you are in your Vocabulary/Un-vocabulary decision.\n",
    "\n",
    "**Output Format:**\n",
    "For every term you are given, you MUST respond in the strict JSON format. Do not add any extra conversation or pleasantries.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6e9798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-14 15:46:11,361 - INFO - Loaded CSV with 2 rows\n",
      "2025-07-14 15:46:11,363 - INFO - Processing row 0: 'soil screening values'\n",
      "2025-07-14 15:46:12,336 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-14 15:46:12,336 - INFO - Row 0: Success - is_vocab_term: True, confidence: 0.93\n",
      "2025-07-14 15:46:13,345 - INFO - Processing row 1: 'soil phosphorus loss'\n",
      "2025-07-14 15:46:13,988 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-07-14 15:46:13,991 - INFO - Row 1: Success - is_vocab_term: True, confidence: 0.93\n",
      "2025-07-14 15:46:14,998 - INFO - Processing complete. Results saved to test_results.csv\n",
      "2025-07-14 15:46:14,999 - INFO - Summary: 2 successful, 0 failed, 2 vocab terms identified\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class TermProcessor:\n",
    "    def __init__(self, system_prompt: str, user_prompt_template: str):\n",
    "        \"\"\"\n",
    "        Initialize the processor with prompts\n",
    "        \n",
    "        Args:\n",
    "            system_prompt: The system prompt (unchanged for all calls)\n",
    "            user_prompt_template: Template for user prompt with {term} placeholder\n",
    "        \"\"\"\n",
    "        self.client = OpenAI()\n",
    "        self.system_prompt = system_prompt\n",
    "        self.user_prompt_template = user_prompt_template\n",
    "        \n",
    "    def get_term_from_row(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Extract the term from a CSV row (preferred label, fallback to alternative label)\n",
    "        \n",
    "        Args:\n",
    "            row: Pandas Series representing a CSV row\n",
    "            \n",
    "        Returns:\n",
    "            The term to process\n",
    "        \"\"\"\n",
    "        # Assuming columns are: URL, preferred_label, alternative_label\n",
    "        preferred_label = row.iloc[1] if len(row) > 1 else \"\"\n",
    "        alternative_label = row.iloc[2] if len(row) > 2 else \"\"\n",
    "        \n",
    "        # Use preferred label if available and not empty, otherwise use alternative\n",
    "        if pd.notna(preferred_label) and str(preferred_label).strip():\n",
    "            return str(preferred_label).strip()\n",
    "        elif pd.notna(alternative_label) and str(alternative_label).strip():\n",
    "            return str(alternative_label).strip()\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    def call_llm_api(self, term: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Call the LLM API with the given term\n",
    "        \n",
    "        Args:\n",
    "            term: The term to evaluate\n",
    "            \n",
    "        Returns:\n",
    "            JSON response from LLM or None if error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create the user prompt with the term\n",
    "            prompt_voc = self.user_prompt_template.format(term=term)\n",
    "            \n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=\"gpt-4.1\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": prompt_voc}\n",
    "                ],\n",
    "                response_format={\n",
    "                    \"type\": \"json_schema\",\n",
    "                    \"json_schema\": {\n",
    "                        \"name\": \"soil_vocab_review\",\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"term\": {\n",
    "                                    \"type\": \"string\",\n",
    "                                    \"description\": \"The specific term being evaluated, exactly as input.\"\n",
    "                                },\n",
    "                                \"is_vocab_term\": {\n",
    "                                    \"type\": \"boolean\",\n",
    "                                    \"description\": \"Whether the term should be included in the controlled vocabulary for soil science.\"\n",
    "                                },\n",
    "                                \"confidence_score\": {\n",
    "                                    \"type\": \"number\",\n",
    "                                    \"description\": \"Confidence score of the judgement, from 0 to 1 (inclusive).\",\n",
    "                                    \"minimum\": 0,\n",
    "                                    \"maximum\": 1\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\n",
    "                                \"term\",\n",
    "                                \"is_vocab_term\",\n",
    "                                \"confidence_score\"\n",
    "                            ],\n",
    "                            \"additionalProperties\": False\n",
    "                        },\n",
    "                        \"strict\": True\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Parse the JSON response\n",
    "            response_content = completion.choices[0].message.content\n",
    "            return json.loads(response_content)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calling LLM API for term '{term}': {str(e)}\")\n",
    "            return None\n",
    "    \n",
    "    def process_csv(self, input_csv_path: str, output_csv_path: str, \n",
    "                   delay_seconds: float = 1.0, resume_from_row: int = 0):\n",
    "        \"\"\"\n",
    "        Process the CSV file and generate results\n",
    "        \n",
    "        Args:\n",
    "            input_csv_path: Path to input CSV file\n",
    "            output_csv_path: Path to output CSV file\n",
    "            delay_seconds: Delay between API calls to respect rate limits\n",
    "            resume_from_row: Row number to resume from (0-indexed)\n",
    "        \"\"\"\n",
    "        # Read the input CSV\n",
    "        try:\n",
    "            df = pd.read_csv(input_csv_path)\n",
    "            logger.info(f\"Loaded CSV with {len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading CSV file: {str(e)}\")\n",
    "            return\n",
    "        \n",
    "        # Prepare results list\n",
    "        results = []\n",
    "        \n",
    "        # Load existing results if resuming\n",
    "        if resume_from_row > 0:\n",
    "            try:\n",
    "                existing_df = pd.read_csv(output_csv_path)\n",
    "                results = existing_df.to_dict('records')\n",
    "                logger.info(f\"Resuming from row {resume_from_row}, loaded {len(results)} existing results\")\n",
    "            except FileNotFoundError:\n",
    "                logger.warning(f\"Output file {output_csv_path} not found, starting fresh\")\n",
    "                resume_from_row = 0\n",
    "        \n",
    "        # Process each row starting from resume_from_row\n",
    "        for idx, row in df.iloc[resume_from_row:].iterrows():\n",
    "            actual_idx = idx if resume_from_row == 0 else resume_from_row + (idx - df.iloc[resume_from_row:].index[0])\n",
    "            \n",
    "            # Get the term from the row\n",
    "            term = self.get_term_from_row(row)\n",
    "            \n",
    "            if not term:\n",
    "                logger.warning(f\"Row {actual_idx}: No valid term found, skipping\")\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"Processing row {actual_idx}: '{term}'\")\n",
    "            \n",
    "            # Call LLM API\n",
    "            result = self.call_llm_api(term)\n",
    "            \n",
    "            if result:\n",
    "                # Add original row data to the result\n",
    "                result['original_url'] = row.iloc[0] if len(row) > 0 else \"\"\n",
    "                result['preferred_label'] = row.iloc[1] if len(row) > 1 else \"\"\n",
    "                result['alternative_label'] = row.iloc[2] if len(row) > 2 else \"\"\n",
    "                result['row_index'] = actual_idx\n",
    "                \n",
    "                results.append(result)\n",
    "                logger.info(f\"Row {actual_idx}: Success - is_vocab_term: {result['is_vocab_term']}, confidence: {result['confidence_score']}\")\n",
    "            else:\n",
    "                # Add error entry\n",
    "                error_result = {\n",
    "                    'term': term,\n",
    "                    'is_vocab_term': None,\n",
    "                    'confidence_score': None,\n",
    "                    'original_url': row.iloc[0] if len(row) > 0 else \"\",\n",
    "                    'preferred_label': row.iloc[1] if len(row) > 1 else \"\",\n",
    "                    'alternative_label': row.iloc[2] if len(row) > 2 else \"\",\n",
    "                    'row_index': actual_idx,\n",
    "                    'error': 'API call failed'\n",
    "                }\n",
    "                results.append(error_result)\n",
    "                logger.error(f\"Row {actual_idx}: Failed to process term '{term}'\")\n",
    "            \n",
    "            # Save results periodically (every 10 rows)\n",
    "            if len(results) % 10 == 0:\n",
    "                self.save_results(results, output_csv_path)\n",
    "                logger.info(f\"Saved intermediate results ({len(results)} rows)\")\n",
    "            \n",
    "            # Delay between API calls\n",
    "            if delay_seconds > 0:\n",
    "                time.sleep(delay_seconds)\n",
    "        \n",
    "        # Save final results\n",
    "        self.save_results(results, output_csv_path)\n",
    "        logger.info(f\"Processing complete. Results saved to {output_csv_path}\")\n",
    "        \n",
    "        # Print summary\n",
    "        successful_calls = sum(1 for r in results if r.get('is_vocab_term') is not None)\n",
    "        failed_calls = len(results) - successful_calls\n",
    "        vocab_terms = sum(1 for r in results if r.get('is_vocab_term') is True)\n",
    "        \n",
    "        logger.info(f\"Summary: {successful_calls} successful, {failed_calls} failed, {vocab_terms} vocab terms identified\")\n",
    "    \n",
    "    def save_results(self, results: list, output_csv_path: str):\n",
    "        \"\"\"Save results to CSV file\"\"\"\n",
    "        try:\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_df.to_csv(output_csv_path, index=False)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving results: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # Configuration\n",
    "    INPUT_CSV_PATH = \"ontovocabs/soil_health_KG.csv\"  # Change this to your input file path\n",
    "    OUTPUT_CSV_PATH = \"llm_results.csv\"  # Change this to your desired output file path\n",
    "    DELAY_SECONDS = 1.0  # Delay between API calls (adjust based on rate limits)\n",
    "    RESUME_FROM_ROW = 0  # Set to row number if resuming from interruption\n",
    "    \n",
    "    # Define your prompts here\n",
    "    SYSTEM_PROMPT = system_prompt_voc\n",
    "    \n",
    "    USER_PROMPT_TEMPLATE = \"\"\"Now please determine if the following term is a vocabulary term or un-vocabulary term: {term}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize processor\n",
    "    processor = TermProcessor(SYSTEM_PROMPT, USER_PROMPT_TEMPLATE)\n",
    "    \n",
    "    # Process the CSV\n",
    "    processor.process_csv(\n",
    "        input_csv_path=INPUT_CSV_PATH,\n",
    "        output_csv_path=OUTPUT_CSV_PATH,\n",
    "        delay_seconds=DELAY_SECONDS,\n",
    "        resume_from_row=RESUME_FROM_ROW\n",
    "    )\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
